Retrieval-Augmented Generation (RAG) System for Legal Document Q&A
This project demonstrates how to build a Retrieval-Augmented Generation (RAG) pipeline that can answer questions about legal documents and retrieve relevant clauses using open-source tools like LangChain, FAISS, and Hugging Face Transformers.

ğŸ” Use case: Automating legal document understanding â€” including contract clause retrieval, regulatory Q&A, and compliance insights.

ğŸš€ Features
âœ… Load and process legal contract datasets.

ğŸ“„ Intelligent document chunking using RecursiveCharacterTextSplitter.

ğŸ” Semantic search via dense embeddings and FAISS vector store.

ğŸ¤– Query answering using LLMs like Mistral-7B or other Hugging Face-hosted models.

ğŸ“š End-to-end RAG pipeline using LangChain.

âš™ï¸ Modular and extendable â€” plug in your own datasets, models, or prompts.

ğŸ§  Technologies Used
LangChain â€“ for chaining retrieval and LLM generation.

SentenceTransformers â€“ for generating text embeddings (MiniLM-L6-v2).

FAISS â€“ for fast similarity search over document chunks.

Transformers (Hugging Face) â€“ to load and run LLMs.

BitsAndBytes â€“ for 4-bit quantized LLM loading.

Google Colab â€“ for development and GPU experimentation.

Folder structure:
.
â”œâ”€â”€ RAG_project3.ipynb       # Jupyter Notebook with full pipeline
â”œâ”€â”€ data/                    # (optional) directory for PDF or text contracts
â”œâ”€â”€ README.md                # You are here!


